{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c88d931c",
   "metadata": {},
   "source": [
    "# CART 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd70a1d",
   "metadata": {},
   "source": [
    "## CART (Classification and Regression Tree)알고리즘 이란?\n",
    "\n",
    "\n",
    "지니계수를 이용해서 Tree알고리즘을 구현한 방식입니다.\n",
    "\n",
    "CART 알고리즘의 특징\n",
    "\n",
    "1. 자식 노드를 두개만 갖는다.\n",
    "2. Regression을 구현 할 수 있다. (불순도를 사용하지 않고 오차를 사용)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dd8e7d",
   "metadata": {},
   "source": [
    "## 지니계수란 ?\n",
    "\n",
    "지니계수는 불순도를 나타내는 지표 중 하나.\n",
    "\n",
    "<img src=\"http://www.learnbymarketing.com/wp-content/uploads/2016/02/gini-index-formula.png\">\n",
    "\n",
    "각 확률간 괴리가 커질 수 록 지니계수가 낮아지는 추세를 보임.\n",
    "\n",
    "예) 이산형 자료에서의 지니계수\n",
    "\n",
    "Case 1) 가슴통증이 있을때(YES) 심장질환이 있다(YES)/없다(NO) 105/39\n",
    "\n",
    "Case 2) 가슴통증이 없을때(NO) 심장질환이 있다(YES)/없다(NO) 39/125\n",
    "\n",
    "이때 두 케이스 지니계수는 1에서 YES의 비율의 제곱과 NO의 비율의 제곱을 뺀것이 됩니다.\n",
    "          \n",
    "따라서, \n",
    "\n",
    "Case 1 의 지니계수는 1 - (105/144)^2 - (39/144)^2 = 0.395\n",
    "\n",
    "Case 2 의 지니계수는 1 - (39/164)^2 - (125/164)^2 = 0.336"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae47288f",
   "metadata": {},
   "source": [
    "# ID3 알고리즘\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd0504a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T13:06:17.396297Z",
     "start_time": "2021-12-05T13:06:17.391297Z"
    }
   },
   "source": [
    "## ID3 알고리즘이란?\n",
    "\n",
    "Iterative Dichotomiser 3의 약자.\n",
    "\n",
    "불순도를 \"엔트로피\"를 이용해서 구하는 알고리즘\n",
    "\n",
    "1. Regression을 구현할수 없다\n",
    "2. 자식노드를 2개이상 분기 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d00b73",
   "metadata": {},
   "source": [
    "## 엔트로피란?\n",
    "\n",
    "<img src =\"https://miro.medium.com/max/1122/0*DkWdyGidNSfdT1Nu.png\">\n",
    "\n",
    "\n",
    "엔트로피 = 확률변수의 놀라움을 측정한 값\n",
    "\n",
    "의사결정 나무에서 엔트로피는\n",
    "\n",
    "분기전 엔트로피(H(S)) - 분기후 엔트로피(H(S,A))로 나타낼 수 있고 이를 Information gain이라고 하며\n",
    "\n",
    "분기 후 엔트로피는 양쪽 가지로 나눠지는 확률 곱하기 엔트로피의 합으로 구할 수 있습니다.\n",
    "\n",
    "최적의 의사결정 나무를 만들기 위해선 분기전 엔트로피(H(S)) - 분기후 엔트로피(H(S,A))의 값이 가장 큰 변수로 분기합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c57f43",
   "metadata": {},
   "source": [
    "# C4.5 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8bf54c",
   "metadata": {},
   "source": [
    "## C4.5 알고리즘 이란?\n",
    "\n",
    "ID3 알고리즘을 개선한 알고리즘\n",
    "\n",
    "1. 정교한 불순도 지표 (Information gain ratio) 활용 -> IV(Intrinsic value) 를 사용하여 개선\n",
    "    \n",
    "    <img src=\"https://blog.kakaocdn.net/dn/nH3Bs/btqYJ81je2y/UPCmNVrkPyaHb9t1Ym8yN1/img.png\">\n",
    "    \n",
    "   Information gain ratio  = IG/IV\n",
    "    \n",
    "\n",
    "2. 범주형 변수 뿐 아니라 연속형 변수를 사용 가능\n",
    "3. 결측치가 포함된 데이터도 사용 가능\n",
    "4. 과적합을 방지하기 위한 가지치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961d9eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1bd8a35",
   "metadata": {},
   "source": [
    "# 자료형 별 Desicion Tree의 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a9aea0",
   "metadata": {},
   "source": [
    "## Desicision Tree 의 학습과정 (이산형 자료)\n",
    "\n",
    "1.  루트 노드가 될 피쳐를 선택한다.\n",
    "\n",
    "피쳐를 통해서 분기된 두 자식노드의 지니계수의 가중평균이 가장 낮은 피쳐가 루트노드로 선택 됨\n",
    "\n",
    "예) 가슴통증에 대한 지니계수의 가중평균은 (144/308)*0.395 + (164/308)*0.336 = 약 0.36\n",
    "\n",
    "2. 자식 노드들을 이용해서 지니계수가 작아지는 방향으로 데이터를 분리해 나간다.\n",
    "\n",
    "    <과정>\n",
    "    \n",
    "    1. 루트노드에서 분기해 나간 자식노드에서도 마찬가지로 지니계수가 가장 적은 피쳐를 이용해서 분기한다.\n",
    "    2. 이 과정을 반복해 나간다.\n",
    "    3. 만약 부모 노드가 자식노드 보다 지니계수가 적다면 분기하지 않는다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b89508",
   "metadata": {},
   "source": [
    "##  Desicision Tree 의 학습과정 (연속형 자료)\n",
    "\n",
    "\n",
    "1. 연속형 자료를 sort한다.\n",
    "2. sort된 자료와 인접한 자료간의 평균을 구한다. 예) 0번 자료와 1번자료의 평균\n",
    "3. 평균을 가지고 평균보다 작은 데이터들이 가지는 타겟값을 이용해서 가장 작은 지니계수를 구해나간다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f27ac9",
   "metadata": {},
   "source": [
    "## Desicision Tree 의 학습과정 (순위형 자료)\n",
    "\n",
    "\n",
    "1. 순위보다 작거나 같은 것을 기준으로 지니계수를 구한다.\n",
    "2. 가장 높은 순위는 모든 자료를 포함하기 때문에 계산하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7ab661",
   "metadata": {},
   "source": [
    "## Desicision Tree 의 학습과정 (범주형 자료)\n",
    "\n",
    "\n",
    "1. 특정 범주를 골랐을때를 기준으로 지니계수를 구한다.\n",
    "2. 이떄 범주 or 범주를 골랐을때도 계산한다.\n",
    "3. 하지만 모든 범주를 골랐을경우는 모든 자료를 포함하기 때문에 계산하지 않는다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
